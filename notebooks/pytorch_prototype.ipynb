{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d9e277a",
   "metadata": {},
   "source": [
    "### Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e004cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16863274",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f060ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/hiv_ic50_featurized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c3f426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'active' column\n",
    "df[\"active\"] = (df[\"standard_value\"] <= 1000).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59efe0b",
   "metadata": {},
   "source": [
    "### Preparation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0881ab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"MolWt\", \"TPSA\", \"NumRotatableBonds\",\n",
    "                \"NumHDonors\", \"NumHAcceptors\", \"NumAromaticRings\", \"LogP\"]\n",
    "X = df[feature_cols].values\n",
    "y = df[\"active\"].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46bba5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f32d4b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85efe774",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34b14f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e4410d",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa0cc9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1=nn.Linear(7,32)\n",
    "        self.fc2=nn.Linear(32,16)\n",
    "        self.fc3=nn.Linear(16,1)\n",
    "    def forward(self,x):\n",
    "        x=self.fc1(x)\n",
    "        x=F.relu(x)\n",
    "        x=self.fc2(x)\n",
    "        x=F.relu(x)\n",
    "        x=self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f37d1d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=7, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (fc3): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model= Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cc789c",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "358034b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss=nn.BCEWithLogitsLoss()\n",
    "optim=torch.optim.Adam(params=model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ffc1959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss= 0.6617494556139101\n",
      "Epoch: 2, loss= 0.6341731093964487\n",
      "Epoch: 3, loss= 0.6172705720055778\n",
      "Epoch: 4, loss= 0.6083100947569001\n",
      "Epoch: 5, loss= 0.6027014841448586\n",
      "Epoch: 6, loss= 0.5954178247811659\n",
      "Epoch: 7, loss= 0.5923750219480046\n",
      "Epoch: 8, loss= 0.587052671189578\n",
      "Epoch: 9, loss= 0.584821982878559\n",
      "Epoch: 10, loss= 0.5796572366975389\n",
      "Epoch: 11, loss= 0.5744554560139494\n",
      "Epoch: 12, loss= 0.5695765769706582\n",
      "Epoch: 13, loss= 0.5648425472232531\n",
      "Epoch: 14, loss= 0.561719904868108\n",
      "Epoch: 15, loss= 0.560495189675745\n",
      "Epoch: 16, loss= 0.5563845715432797\n",
      "Epoch: 17, loss= 0.5555643990354718\n",
      "Epoch: 18, loss= 0.5519083750697802\n",
      "Epoch: 19, loss= 0.5483724992230253\n",
      "Epoch: 20, loss= 0.5428025704509807\n",
      "Epoch: 21, loss= 0.5387425988350274\n",
      "Epoch: 22, loss= 0.5392518049141146\n",
      "Epoch: 23, loss= 0.5344523821236953\n",
      "Epoch: 24, loss= 0.5393730684271398\n",
      "Epoch: 25, loss= 0.5303383236786104\n",
      "Epoch: 26, loss= 0.5288423777751203\n",
      "Epoch: 27, loss= 0.5265977959587889\n",
      "Epoch: 28, loss= 0.5226476987577834\n",
      "Epoch: 29, loss= 0.5285525982110005\n",
      "Epoch: 30, loss= 0.5226908648913762\n",
      "Epoch: 31, loss= 0.5202593389547097\n",
      "Epoch: 32, loss= 0.5215101898841138\n",
      "Epoch: 33, loss= 0.5208055273541864\n",
      "Epoch: 34, loss= 0.5229910299463092\n",
      "Epoch: 35, loss= 0.5165730224465425\n",
      "Epoch: 36, loss= 0.5185025660496838\n",
      "Epoch: 37, loss= 0.5137027861937037\n",
      "Epoch: 38, loss= 0.516417384147644\n",
      "Epoch: 39, loss= 0.5131621022269411\n",
      "Epoch: 40, loss= 0.511243223581674\n",
      "Epoch: 41, loss= 0.5067596017189746\n",
      "Epoch: 42, loss= 0.5050111975309983\n",
      "Epoch: 43, loss= 0.5054924953658626\n",
      "Epoch: 44, loss= 0.5122422193581203\n",
      "Epoch: 45, loss= 0.5093966035910372\n",
      "Epoch: 46, loss= 0.5109466122006471\n",
      "Epoch: 47, loss= 0.5036628634299872\n",
      "Epoch: 48, loss= 0.5039689752290833\n",
      "Epoch: 49, loss= 0.5052769575478896\n",
      "Epoch: 50, loss= 0.5006032010294357\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    loss_runnig=0\n",
    "    for features,label in train_loader:\n",
    "        optim.zero_grad()\n",
    "        predict=model(features)\n",
    "        perte=Loss(predict,label)\n",
    "        loss_runnig+=perte.item()\n",
    "        perte.backward()\n",
    "        optim.step()\n",
    "    print(f\"Epoch: {epoch+1}, loss= {loss_runnig/len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4048a4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5\n",
      "Accuracy:  0.7540\n",
      "Precision: 0.7427\n",
      "Recall:    0.7871\n",
      "F1-score:  0.7643\n",
      "ROC AUC:   0.8352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7540208136234626,\n",
       " 0.7427312775330397,\n",
       " 0.7871148459383753,\n",
       " 0.7642792384406165,\n",
       " 0.8351680717029542)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import torch\n",
    "\n",
    "def evaluate_model(model, data_loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, labels in data_loader:\n",
    "            outputs = model(features)\n",
    "            probs = torch.sigmoid(outputs)  # convert logits in probabilities\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    all_labels = np.array(all_labels).reshape(-1)\n",
    "    all_probs = np.array(all_probs).reshape(-1)\n",
    "    \n",
    "\n",
    "    preds = (all_probs >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(all_labels, preds)\n",
    "    prec = precision_score(all_labels, preds)\n",
    "    rec = recall_score(all_labels, preds)\n",
    "    f1 = f1_score(all_labels, preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    \n",
    "    print(f\"Threshold: {threshold}\")\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1-score:  {f1:.4f}\")\n",
    "    print(f\"ROC AUC:   {auc:.4f}\")\n",
    "    \n",
    "    return acc, prec, rec, f1, auc\n",
    "\n",
    "\n",
    "evaluate_model(model, test_loader, threshold=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d5c5ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 0.7697262479871175\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def best_f1_threshold(probs, labels):\n",
    "    ts = np.linspace(0.05, 0.95, 19)\n",
    "    scores = [(t, f1_score(labels, (probs>=t).astype(int))) for t in ts]\n",
    "    return max(scores, key=lambda x: x[1])\n",
    "\n",
    "# reuse outputs from evaluate pass (all_probs, all_labels)\n",
    "_ = model.eval()\n",
    "# quick pass to get probs & labels\n",
    "all_probs, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for Xb, yb in test_loader:\n",
    "        all_probs.extend(torch.sigmoid(model(Xb)).cpu().numpy().ravel())\n",
    "        all_labels.extend(yb.cpu().numpy().ravel())\n",
    "best_t, best_f1 = best_f1_threshold(np.array(all_probs), np.array(all_labels))\n",
    "print(best_t, best_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0768ccf6",
   "metadata": {},
   "source": [
    "Let's try the new threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ade8bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.35\n",
      "Accuracy:  0.7294\n",
      "Precision: 0.6766\n",
      "Recall:    0.8926\n",
      "F1-score:  0.7697\n",
      "ROC AUC:   0.8352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7294228949858089,\n",
       " 0.6765746638358103,\n",
       " 0.892623716153128,\n",
       " 0.7697262479871175,\n",
       " 0.8351680717029542)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import torch\n",
    "\n",
    "def evaluate_model(model, data_loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, labels in data_loader:\n",
    "            outputs = model(features)\n",
    "            probs = torch.sigmoid(outputs)  # convert logits in probabilities\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    all_labels = np.array(all_labels).reshape(-1)\n",
    "    all_probs = np.array(all_probs).reshape(-1)\n",
    "    \n",
    "    \n",
    "    preds = (all_probs >= threshold).astype(int)\n",
    "    \n",
    "   \n",
    "    acc = accuracy_score(all_labels, preds)\n",
    "    prec = precision_score(all_labels, preds)\n",
    "    rec = recall_score(all_labels, preds)\n",
    "    f1 = f1_score(all_labels, preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    \n",
    "    print(f\"Threshold: {threshold}\")\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1-score:  {f1:.4f}\")\n",
    "    print(f\"ROC AUC:   {auc:.4f}\")\n",
    "    \n",
    "    return acc, prec, rec, f1, auc\n",
    "\n",
    "\n",
    "evaluate_model(model, test_loader, threshold=0.35)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
